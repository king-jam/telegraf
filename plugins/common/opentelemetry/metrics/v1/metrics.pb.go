// Code generated by protoc-gen-gogo. DO NOT EDIT.
// source: opentelemetry/proto/metrics/v1/metrics.proto

package v1

import (
	fmt "fmt"
	proto "github.com/gogo/protobuf/proto"
	v11 "github.com/influxdata/telegraf/plugins/common/opentelemetry/common/v1"
	v1 "github.com/influxdata/telegraf/plugins/common/opentelemetry/resource/v1"
	math "math"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.GoGoProtoPackageIsVersion3 // please upgrade the proto package

// AggregationTemporality defines how a metric aggregator reports aggregated
// values. It describes how those values relate to the time interval over
// which they are aggregated.
type AggregationTemporality int32

const (
	// UNSPECIFIED is the default AggregationTemporality, it MUST not be used.
	AggregationTemporality_AGGREGATION_TEMPORALITY_UNSPECIFIED AggregationTemporality = 0
	// DELTA is an AggregationTemporality for a metric aggregator which reports
	// changes since last report time. Successive metrics contain aggregation of
	// values from continuous and non-overlapping intervals.
	//
	// The values for a DELTA metric are based only on the time interval
	// associated with one measurement cycle. There is no dependency on
	// previous measurements like is the case for CUMULATIVE metrics.
	//
	// For example, consider a system measuring the number of requests that
	// it receives and reports the sum of these requests every second as a
	// DELTA metric:
	//
	//   1. The system starts receiving at time=t_0.
	//   2. A request is received, the system measures 1 request.
	//   3. A request is received, the system measures 1 request.
	//   4. A request is received, the system measures 1 request.
	//   5. The 1 second collection cycle ends. A metric is exported for the
	//      number of requests received over the interval of time t_0 to
	//      t_0+1 with a value of 3.
	//   6. A request is received, the system measures 1 request.
	//   7. A request is received, the system measures 1 request.
	//   8. The 1 second collection cycle ends. A metric is exported for the
	//      number of requests received over the interval of time t_0+1 to
	//      t_0+2 with a value of 2.
	AggregationTemporality_AGGREGATION_TEMPORALITY_DELTA AggregationTemporality = 1
	// CUMULATIVE is an AggregationTemporality for a metric aggregator which
	// reports changes since a fixed start time. This means that current values
	// of a CUMULATIVE metric depend on all previous measurements since the
	// start time. Because of this, the sender is required to retain this state
	// in some form. If this state is lost or invalidated, the CUMULATIVE metric
	// values MUST be reset and a new fixed start time following the last
	// reported measurement time sent MUST be used.
	//
	// For example, consider a system measuring the number of requests that
	// it receives and reports the sum of these requests every second as a
	// CUMULATIVE metric:
	//
	//   1. The system starts receiving at time=t_0.
	//   2. A request is received, the system measures 1 request.
	//   3. A request is received, the system measures 1 request.
	//   4. A request is received, the system measures 1 request.
	//   5. The 1 second collection cycle ends. A metric is exported for the
	//      number of requests received over the interval of time t_0 to
	//      t_0+1 with a value of 3.
	//   6. A request is received, the system measures 1 request.
	//   7. A request is received, the system measures 1 request.
	//   8. The 1 second collection cycle ends. A metric is exported for the
	//      number of requests received over the interval of time t_0 to
	//      t_0+2 with a value of 5.
	//   9. The system experiences a fault and loses state.
	//   10. The system recovers and resumes receiving at time=t_1.
	//   11. A request is received, the system measures 1 request.
	//   12. The 1 second collection cycle ends. A metric is exported for the
	//      number of requests received over the interval of time t_1 to
	//      t_0+1 with a value of 1.
	//
	// Note: Even though, when reporting changes since last report time, using
	// CUMULATIVE is valid, it is not recommended. This may cause problems for
	// systems that do not use start_time to determine when the aggregation
	// value was reset (e.g. Prometheus).
	AggregationTemporality_AGGREGATION_TEMPORALITY_CUMULATIVE AggregationTemporality = 2
)

var AggregationTemporality_name = map[int32]string{
	0: "AGGREGATION_TEMPORALITY_UNSPECIFIED",
	1: "AGGREGATION_TEMPORALITY_DELTA",
	2: "AGGREGATION_TEMPORALITY_CUMULATIVE",
}

var AggregationTemporality_value = map[string]int32{
	"AGGREGATION_TEMPORALITY_UNSPECIFIED": 0,
	"AGGREGATION_TEMPORALITY_DELTA":       1,
	"AGGREGATION_TEMPORALITY_CUMULATIVE":  2,
}

func (x AggregationTemporality) String() string {
	return proto.EnumName(AggregationTemporality_name, int32(x))
}

func (AggregationTemporality) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_3c3112f9fa006917, []int{0}
}

// A collection of InstrumentationLibraryMetrics from a Resource.
type ResourceMetrics struct {
	// The resource for the metrics in this message.
	// If this field is not set then no resource info is known.
	Resource *v1.Resource `protobuf:"bytes,1,opt,name=resource,proto3" json:"resource,omitempty"`
	// A list of metrics that originate from a resource.
	InstrumentationLibraryMetrics []*InstrumentationLibraryMetrics `protobuf:"bytes,2,rep,name=instrumentation_library_metrics,json=instrumentationLibraryMetrics,proto3" json:"instrumentation_library_metrics,omitempty"`
	XXX_NoUnkeyedLiteral          struct{}                         `json:"-"`
	XXX_unrecognized              []byte                           `json:"-"`
	XXX_sizecache                 int32                            `json:"-"`
}

func (m *ResourceMetrics) Reset()         { *m = ResourceMetrics{} }
func (m *ResourceMetrics) String() string { return proto.CompactTextString(m) }
func (*ResourceMetrics) ProtoMessage()    {}
func (*ResourceMetrics) Descriptor() ([]byte, []int) {
	return fileDescriptor_3c3112f9fa006917, []int{0}
}
func (m *ResourceMetrics) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_ResourceMetrics.Unmarshal(m, b)
}
func (m *ResourceMetrics) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_ResourceMetrics.Marshal(b, m, deterministic)
}
func (m *ResourceMetrics) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ResourceMetrics.Merge(m, src)
}
func (m *ResourceMetrics) XXX_Size() int {
	return xxx_messageInfo_ResourceMetrics.Size(m)
}
func (m *ResourceMetrics) XXX_DiscardUnknown() {
	xxx_messageInfo_ResourceMetrics.DiscardUnknown(m)
}

var xxx_messageInfo_ResourceMetrics proto.InternalMessageInfo

func (m *ResourceMetrics) GetResource() *v1.Resource {
	if m != nil {
		return m.Resource
	}
	return nil
}

func (m *ResourceMetrics) GetInstrumentationLibraryMetrics() []*InstrumentationLibraryMetrics {
	if m != nil {
		return m.InstrumentationLibraryMetrics
	}
	return nil
}

// A collection of Metrics produced by an InstrumentationLibrary.
type InstrumentationLibraryMetrics struct {
	// The instrumentation library information for the metrics in this message.
	// Semantically when InstrumentationLibrary isn't set, it is equivalent with
	// an empty instrumentation library name (unknown).
	InstrumentationLibrary *v11.InstrumentationLibrary `protobuf:"bytes,1,opt,name=instrumentation_library,json=instrumentationLibrary,proto3" json:"instrumentation_library,omitempty"`
	// A list of metrics that originate from an instrumentation library.
	Metrics              []*Metric `protobuf:"bytes,2,rep,name=metrics,proto3" json:"metrics,omitempty"`
	XXX_NoUnkeyedLiteral struct{}  `json:"-"`
	XXX_unrecognized     []byte    `json:"-"`
	XXX_sizecache        int32     `json:"-"`
}

func (m *InstrumentationLibraryMetrics) Reset()         { *m = InstrumentationLibraryMetrics{} }
func (m *InstrumentationLibraryMetrics) String() string { return proto.CompactTextString(m) }
func (*InstrumentationLibraryMetrics) ProtoMessage()    {}
func (*InstrumentationLibraryMetrics) Descriptor() ([]byte, []int) {
	return fileDescriptor_3c3112f9fa006917, []int{1}
}
func (m *InstrumentationLibraryMetrics) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_InstrumentationLibraryMetrics.Unmarshal(m, b)
}
func (m *InstrumentationLibraryMetrics) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_InstrumentationLibraryMetrics.Marshal(b, m, deterministic)
}
func (m *InstrumentationLibraryMetrics) XXX_Merge(src proto.Message) {
	xxx_messageInfo_InstrumentationLibraryMetrics.Merge(m, src)
}
func (m *InstrumentationLibraryMetrics) XXX_Size() int {
	return xxx_messageInfo_InstrumentationLibraryMetrics.Size(m)
}
func (m *InstrumentationLibraryMetrics) XXX_DiscardUnknown() {
	xxx_messageInfo_InstrumentationLibraryMetrics.DiscardUnknown(m)
}

var xxx_messageInfo_InstrumentationLibraryMetrics proto.InternalMessageInfo

func (m *InstrumentationLibraryMetrics) GetInstrumentationLibrary() *v11.InstrumentationLibrary {
	if m != nil {
		return m.InstrumentationLibrary
	}
	return nil
}

func (m *InstrumentationLibraryMetrics) GetMetrics() []*Metric {
	if m != nil {
		return m.Metrics
	}
	return nil
}

// Defines a Metric which has one or more timeseries.
//
// The data model and relation between entities is shown in the
// diagram below. Here, "DataPoint" is the term used to refer to any
// one of the specific data point value types, and "points" is the term used
// to refer to any one of the lists of points contained in the Metric.
//
// - Metric is composed of a metadata and data.
// - Metadata part contains a name, description, unit.
// - Data is one of the possible types (Gauge, Sum, Histogram, etc.).
// - DataPoint contains timestamps, labels, and one of the possible value type
//   fields.
//
//     Metric
//  +------------+
//  |name        |
//  |description |
//  |unit        |     +------------------------------------+
//  |data        |---> |Gauge, Sum, Histogram, Summary, ... |
//  +------------+     +------------------------------------+
//
//    Data [One of Gauge, Sum, Histogram, Summary, ...]
//  +-----------+
//  |...        |  // Metadata about the Data.
//  |points     |--+
//  +-----------+  |
//                 |      +---------------------------+
//                 |      |DataPoint 1                |
//                 v      |+------+------+   +------+ |
//              +-----+   ||label |label |...|label | |
//              |  1  |-->||value1|value2|...|valueN| |
//              +-----+   |+------+------+   +------+ |
//              |  .  |   |+-----+                    |
//              |  .  |   ||value|                    |
//              |  .  |   |+-----+                    |
//              |  .  |   +---------------------------+
//              |  .  |                   .
//              |  .  |                   .
//              |  .  |                   .
//              |  .  |   +---------------------------+
//              |  .  |   |DataPoint M                |
//              +-----+   |+------+------+   +------+ |
//              |  M  |-->||label |label |...|label | |
//              +-----+   ||value1|value2|...|valueN| |
//                        |+------+------+   +------+ |
//                        |+-----+                    |
//                        ||value|                    |
//                        |+-----+                    |
//                        +---------------------------+
//
// All DataPoint types have three common fields:
// - Labels zero or more key-value pairs associated with the data point.
// - StartTimeUnixNano MUST be set to the start of the interval when the data's
//   type includes an AggregationTemporality. This field is not set otherwise.
// - TimeUnixNano MUST be set to:
//   - the moment when an aggregation is reported (independent of the
//     aggregation temporality).
//   - the instantaneous time of the event.
type Metric struct {
	// name of the metric, including its DNS name prefix. It must be unique.
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// description of the metric, which can be used in documentation.
	Description string `protobuf:"bytes,2,opt,name=description,proto3" json:"description,omitempty"`
	// unit in which the metric value is reported. Follows the format
	// described by http://unitsofmeasure.org/ucum.html.
	Unit string `protobuf:"bytes,3,opt,name=unit,proto3" json:"unit,omitempty"`
	// Data determines the aggregation type (if any) of the metric, what is the
	// reported value type for the data points, as well as the relatationship to
	// the time interval over which they are reported.
	//
	// TODO: Update table after the decision on:
	// https://github.com/open-telemetry/opentelemetry-specification/issues/731.
	// By default, metrics recording using the OpenTelemetry API are exported as
	// (the table does not include MeasurementValueType to avoid extra rows):
	//
	//   Instrument         Type
	//   ----------------------------------------------
	//   Counter            Sum(aggregation_temporality=delta;is_monotonic=true)
	//   UpDownCounter      Sum(aggregation_temporality=delta;is_monotonic=false)
	//   ValueRecorder      TBD
	//   SumObserver        Sum(aggregation_temporality=cumulative;is_monotonic=true)
	//   UpDownSumObserver  Sum(aggregation_temporality=cumulative;is_monotonic=false)
	//   ValueObserver      Gauge()
	//
	// Types that are valid to be assigned to Data:
	//	*Metric_IntGauge
	//	*Metric_DoubleGauge
	//	*Metric_IntSum
	//	*Metric_DoubleSum
	//	*Metric_IntHistogram
	//	*Metric_DoubleHistogram
	//	*Metric_DoubleSummary
	Data                 isMetric_Data `protobuf_oneof:"data"`
	XXX_NoUnkeyedLiteral struct{}      `json:"-"`
	XXX_unrecognized     []byte        `json:"-"`
	XXX_sizecache        int32         `json:"-"`
}

func (m *Metric) Reset()         { *m = Metric{} }
func (m *Metric) String() string { return proto.CompactTextString(m) }
func (*Metric) ProtoMessage()    {}
func (*Metric) Descriptor() ([]byte, []int) {
	return fileDescriptor_3c3112f9fa006917, []int{2}
}
func (m *Metric) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_Metric.Unmarshal(m, b)
}
func (m *Metric) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_Metric.Marshal(b, m, deterministic)
}
func (m *Metric) XXX_Merge(src proto.Message) {
	xxx_messageInfo_Metric.Merge(m, src)
}
func (m *Metric) XXX_Size() int {
	return xxx_messageInfo_Metric.Size(m)
}
func (m *Metric) XXX_DiscardUnknown() {
	xxx_messageInfo_Metric.DiscardUnknown(m)
}

var xxx_messageInfo_Metric proto.InternalMessageInfo

type isMetric_Data interface {
	isMetric_Data()
}

type Metric_IntGauge struct {
	IntGauge *IntGauge `protobuf:"bytes,4,opt,name=int_gauge,json=intGauge,proto3,oneof" json:"int_gauge,omitempty"`
}
type Metric_DoubleGauge struct {
	DoubleGauge *DoubleGauge `protobuf:"bytes,5,opt,name=double_gauge,json=doubleGauge,proto3,oneof" json:"double_gauge,omitempty"`
}
type Metric_IntSum struct {
	IntSum *IntSum `protobuf:"bytes,6,opt,name=int_sum,json=intSum,proto3,oneof" json:"int_sum,omitempty"`
}
type Metric_DoubleSum struct {
	DoubleSum *DoubleSum `protobuf:"bytes,7,opt,name=double_sum,json=doubleSum,proto3,oneof" json:"double_sum,omitempty"`
}
type Metric_IntHistogram struct {
	IntHistogram *IntHistogram `protobuf:"bytes,8,opt,name=int_histogram,json=intHistogram,proto3,oneof" json:"int_histogram,omitempty"`
}
type Metric_DoubleHistogram struct {
	DoubleHistogram *DoubleHistogram `protobuf:"bytes,9,opt,name=double_histogram,json=doubleHistogram,proto3,oneof" json:"double_histogram,omitempty"`
}
type Metric_DoubleSummary struct {
	DoubleSummary *DoubleSummary `protobuf:"bytes,11,opt,name=double_summary,json=doubleSummary,proto3,oneof" json:"double_summary,omitempty"`
}

func (*Metric_IntGauge) isMetric_Data()        {}
func (*Metric_DoubleGauge) isMetric_Data()     {}
func (*Metric_IntSum) isMetric_Data()          {}
func (*Metric_DoubleSum) isMetric_Data()       {}
func (*Metric_IntHistogram) isMetric_Data()    {}
func (*Metric_DoubleHistogram) isMetric_Data() {}
func (*Metric_DoubleSummary) isMetric_Data()   {}

func (m *Metric) GetData() isMetric_Data {
	if m != nil {
		return m.Data
	}
	return nil
}

func (m *Metric) GetName() string {
	if m != nil {
		return m.Name
	}
	return ""
}

func (m *Metric) GetDescription() string {
	if m != nil {
		return m.Description
	}
	return ""
}

func (m *Metric) GetUnit() string {
	if m != nil {
		return m.Unit
	}
	return ""
}

func (m *Metric) GetIntGauge() *IntGauge {
	if x, ok := m.GetData().(*Metric_IntGauge); ok {
		return x.IntGauge
	}
	return nil
}

func (m *Metric) GetDoubleGauge() *DoubleGauge {
	if x, ok := m.GetData().(*Metric_DoubleGauge); ok {
		return x.DoubleGauge
	}
	return nil
}

func (m *Metric) GetIntSum() *IntSum {
	if x, ok := m.GetData().(*Metric_IntSum); ok {
		return x.IntSum
	}
	return nil
}

func (m *Metric) GetDoubleSum() *DoubleSum {
	if x, ok := m.GetData().(*Metric_DoubleSum); ok {
		return x.DoubleSum
	}
	return nil
}

func (m *Metric) GetIntHistogram() *IntHistogram {
	if x, ok := m.GetData().(*Metric_IntHistogram); ok {
		return x.IntHistogram
	}
	return nil
}

func (m *Metric) GetDoubleHistogram() *DoubleHistogram {
	if x, ok := m.GetData().(*Metric_DoubleHistogram); ok {
		return x.DoubleHistogram
	}
	return nil
}

func (m *Metric) GetDoubleSummary() *DoubleSummary {
	if x, ok := m.GetData().(*Metric_DoubleSummary); ok {
		return x.DoubleSummary
	}
	return nil
}

// XXX_OneofWrappers is for the internal use of the proto package.
func (*Metric) XXX_OneofWrappers() []interface{} {
	return []interface{}{
		(*Metric_IntGauge)(nil),
		(*Metric_DoubleGauge)(nil),
		(*Metric_IntSum)(nil),
		(*Metric_DoubleSum)(nil),
		(*Metric_IntHistogram)(nil),
		(*Metric_DoubleHistogram)(nil),
		(*Metric_DoubleSummary)(nil),
	}
}

// Gauge represents the type of a int scalar metric that always exports the
// "current value" for every data point. It should be used for an "unknown"
// aggregation.
//
// A Gauge does not support different aggregation temporalities. Given the
// aggregation is unknown, points cannot be combined using the same
// aggregation, regardless of aggregation temporalities. Therefore,
// AggregationTemporality is not included. Consequently, this also means
// "StartTimeUnixNano" is ignored for all data points.
type IntGauge struct {
	DataPoints           []*IntDataPoint `protobuf:"bytes,1,rep,name=data_points,json=dataPoints,proto3" json:"data_points,omitempty"`
	XXX_NoUnkeyedLiteral struct{}        `json:"-"`
	XXX_unrecognized     []byte          `json:"-"`
	XXX_sizecache        int32           `json:"-"`
}

func (m *IntGauge) Reset()         { *m = IntGauge{} }
func (m *IntGauge) String() string { return proto.CompactTextString(m) }
func (*IntGauge) ProtoMessage()    {}
func (*IntGauge) Descriptor() ([]byte, []int) {
	return fileDescriptor_3c3112f9fa006917, []int{3}
}
func (m *IntGauge) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_IntGauge.Unmarshal(m, b)
}
func (m *IntGauge) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_IntGauge.Marshal(b, m, deterministic)
}
func (m *IntGauge) XXX_Merge(src proto.Message) {
	xxx_messageInfo_IntGauge.Merge(m, src)
}
func (m *IntGauge) XXX_Size() int {
	return xxx_messageInfo_IntGauge.Size(m)
}
func (m *IntGauge) XXX_DiscardUnknown() {
	xxx_messageInfo_IntGauge.DiscardUnknown(m)
}

var xxx_messageInfo_IntGauge proto.InternalMessageInfo

func (m *IntGauge) GetDataPoints() []*IntDataPoint {
	if m != nil {
		return m.DataPoints
	}
	return nil
}

// Gauge represents the type of a double scalar metric that always exports the
// "current value" for every data point. It should be used for an "unknown"
// aggregation.
//
// A Gauge does not support different aggregation temporalities. Given the
// aggregation is unknown, points cannot be combined using the same
// aggregation, regardless of aggregation temporalities. Therefore,
// AggregationTemporality is not included. Consequently, this also means
// "StartTimeUnixNano" is ignored for all data points.
type DoubleGauge struct {
	DataPoints           []*DoubleDataPoint `protobuf:"bytes,1,rep,name=data_points,json=dataPoints,proto3" json:"data_points,omitempty"`
	XXX_NoUnkeyedLiteral struct{}           `json:"-"`
	XXX_unrecognized     []byte             `json:"-"`
	XXX_sizecache        int32              `json:"-"`
}

func (m *DoubleGauge) Reset()         { *m = DoubleGauge{} }
func (m *DoubleGauge) String() string { return proto.CompactTextString(m) }
func (*DoubleGauge) ProtoMessage()    {}
func (*DoubleGauge) Descriptor() ([]byte, []int) {
	return fileDescriptor_3c3112f9fa006917, []int{4}
}
func (m *DoubleGauge) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_DoubleGauge.Unmarshal(m, b)
}
func (m *DoubleGauge) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_DoubleGauge.Marshal(b, m, deterministic)
}
func (m *DoubleGauge) XXX_Merge(src proto.Message) {
	xxx_messageInfo_DoubleGauge.Merge(m, src)
}
func (m *DoubleGauge) XXX_Size() int {
	return xxx_messageInfo_DoubleGauge.Size(m)
}
func (m *DoubleGauge) XXX_DiscardUnknown() {
	xxx_messageInfo_DoubleGauge.DiscardUnknown(m)
}

var xxx_messageInfo_DoubleGauge proto.InternalMessageInfo

func (m *DoubleGauge) GetDataPoints() []*DoubleDataPoint {
	if m != nil {
		return m.DataPoints
	}
	return nil
}

// Sum represents the type of a numeric int scalar metric that is calculated as
// a sum of all reported measurements over a time interval.
type IntSum struct {
	DataPoints []*IntDataPoint `protobuf:"bytes,1,rep,name=data_points,json=dataPoints,proto3" json:"data_points,omitempty"`
	// aggregation_temporality describes if the aggregator reports delta changes
	// since last report time, or cumulative changes since a fixed start time.
	AggregationTemporality AggregationTemporality `protobuf:"varint,2,opt,name=aggregation_temporality,json=aggregationTemporality,proto3,enum=opentelemetry.proto.metrics.v1.AggregationTemporality" json:"aggregation_temporality,omitempty"`
	// If "true" means that the sum is monotonic.
	IsMonotonic          bool     `protobuf:"varint,3,opt,name=is_monotonic,json=isMonotonic,proto3" json:"is_monotonic,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *IntSum) Reset()         { *m = IntSum{} }
func (m *IntSum) String() string { return proto.CompactTextString(m) }
func (*IntSum) ProtoMessage()    {}
func (*IntSum) Descriptor() ([]byte, []int) {
	return fileDescriptor_3c3112f9fa006917, []int{5}
}
func (m *IntSum) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_IntSum.Unmarshal(m, b)
}
func (m *IntSum) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_IntSum.Marshal(b, m, deterministic)
}
func (m *IntSum) XXX_Merge(src proto.Message) {
	xxx_messageInfo_IntSum.Merge(m, src)
}
func (m *IntSum) XXX_Size() int {
	return xxx_messageInfo_IntSum.Size(m)
}
func (m *IntSum) XXX_DiscardUnknown() {
	xxx_messageInfo_IntSum.DiscardUnknown(m)
}

var xxx_messageInfo_IntSum proto.InternalMessageInfo

func (m *IntSum) GetDataPoints() []*IntDataPoint {
	if m != nil {
		return m.DataPoints
	}
	return nil
}

func (m *IntSum) GetAggregationTemporality() AggregationTemporality {
	if m != nil {
		return m.AggregationTemporality
	}
	return AggregationTemporality_AGGREGATION_TEMPORALITY_UNSPECIFIED
}

func (m *IntSum) GetIsMonotonic() bool {
	if m != nil {
		return m.IsMonotonic
	}
	return false
}

// Sum represents the type of a numeric double scalar metric that is calculated
// as a sum of all reported measurements over a time interval.
type DoubleSum struct {
	DataPoints []*DoubleDataPoint `protobuf:"bytes,1,rep,name=data_points,json=dataPoints,proto3" json:"data_points,omitempty"`
	// aggregation_temporality describes if the aggregator reports delta changes
	// since last report time, or cumulative changes since a fixed start time.
	AggregationTemporality AggregationTemporality `protobuf:"varint,2,opt,name=aggregation_temporality,json=aggregationTemporality,proto3,enum=opentelemetry.proto.metrics.v1.AggregationTemporality" json:"aggregation_temporality,omitempty"`
	// If "true" means that the sum is monotonic.
	IsMonotonic          bool     `protobuf:"varint,3,opt,name=is_monotonic,json=isMonotonic,proto3" json:"is_monotonic,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *DoubleSum) Reset()         { *m = DoubleSum{} }
func (m *DoubleSum) String() string { return proto.CompactTextString(m) }
func (*DoubleSum) ProtoMessage()    {}
func (*DoubleSum) Descriptor() ([]byte, []int) {
	return fileDescriptor_3c3112f9fa006917, []int{6}
}
func (m *DoubleSum) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_DoubleSum.Unmarshal(m, b)
}
func (m *DoubleSum) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_DoubleSum.Marshal(b, m, deterministic)
}
func (m *DoubleSum) XXX_Merge(src proto.Message) {
	xxx_messageInfo_DoubleSum.Merge(m, src)
}
func (m *DoubleSum) XXX_Size() int {
	return xxx_messageInfo_DoubleSum.Size(m)
}
func (m *DoubleSum) XXX_DiscardUnknown() {
	xxx_messageInfo_DoubleSum.DiscardUnknown(m)
}

var xxx_messageInfo_DoubleSum proto.InternalMessageInfo

func (m *DoubleSum) GetDataPoints() []*DoubleDataPoint {
	if m != nil {
		return m.DataPoints
	}
	return nil
}

func (m *DoubleSum) GetAggregationTemporality() AggregationTemporality {
	if m != nil {
		return m.AggregationTemporality
	}
	return AggregationTemporality_AGGREGATION_TEMPORALITY_UNSPECIFIED
}

func (m *DoubleSum) GetIsMonotonic() bool {
	if m != nil {
		return m.IsMonotonic
	}
	return false
}

// Represents the type of a metric that is calculated by aggregating as a
// Histogram of all reported int measurements over a time interval.
type IntHistogram struct {
	DataPoints []*IntHistogramDataPoint `protobuf:"bytes,1,rep,name=data_points,json=dataPoints,proto3" json:"data_points,omitempty"`
	// aggregation_temporality describes if the aggregator reports delta changes
	// since last report time, or cumulative changes since a fixed start time.
	AggregationTemporality AggregationTemporality `protobuf:"varint,2,opt,name=aggregation_temporality,json=aggregationTemporality,proto3,enum=opentelemetry.proto.metrics.v1.AggregationTemporality" json:"aggregation_temporality,omitempty"`
	XXX_NoUnkeyedLiteral   struct{}               `json:"-"`
	XXX_unrecognized       []byte                 `json:"-"`
	XXX_sizecache          int32                  `json:"-"`
}

func (m *IntHistogram) Reset()         { *m = IntHistogram{} }
func (m *IntHistogram) String() string { return proto.CompactTextString(m) }
func (*IntHistogram) ProtoMessage()    {}
func (*IntHistogram) Descriptor() ([]byte, []int) {
	return fileDescriptor_3c3112f9fa006917, []int{7}
}
func (m *IntHistogram) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_IntHistogram.Unmarshal(m, b)
}
func (m *IntHistogram) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_IntHistogram.Marshal(b, m, deterministic)
}
func (m *IntHistogram) XXX_Merge(src proto.Message) {
	xxx_messageInfo_IntHistogram.Merge(m, src)
}
func (m *IntHistogram) XXX_Size() int {
	return xxx_messageInfo_IntHistogram.Size(m)
}
func (m *IntHistogram) XXX_DiscardUnknown() {
	xxx_messageInfo_IntHistogram.DiscardUnknown(m)
}

var xxx_messageInfo_IntHistogram proto.InternalMessageInfo

func (m *IntHistogram) GetDataPoints() []*IntHistogramDataPoint {
	if m != nil {
		return m.DataPoints
	}
	return nil
}

func (m *IntHistogram) GetAggregationTemporality() AggregationTemporality {
	if m != nil {
		return m.AggregationTemporality
	}
	return AggregationTemporality_AGGREGATION_TEMPORALITY_UNSPECIFIED
}

// Represents the type of a metric that is calculated by aggregating as a
// Histogram of all reported double measurements over a time interval.
type DoubleHistogram struct {
	DataPoints []*DoubleHistogramDataPoint `protobuf:"bytes,1,rep,name=data_points,json=dataPoints,proto3" json:"data_points,omitempty"`
	// aggregation_temporality describes if the aggregator reports delta changes
	// since last report time, or cumulative changes since a fixed start time.
	AggregationTemporality AggregationTemporality `protobuf:"varint,2,opt,name=aggregation_temporality,json=aggregationTemporality,proto3,enum=opentelemetry.proto.metrics.v1.AggregationTemporality" json:"aggregation_temporality,omitempty"`
	XXX_NoUnkeyedLiteral   struct{}               `json:"-"`
	XXX_unrecognized       []byte                 `json:"-"`
	XXX_sizecache          int32                  `json:"-"`
}

func (m *DoubleHistogram) Reset()         { *m = DoubleHistogram{} }
func (m *DoubleHistogram) String() string { return proto.CompactTextString(m) }
func (*DoubleHistogram) ProtoMessage()    {}
func (*DoubleHistogram) Descriptor() ([]byte, []int) {
	return fileDescriptor_3c3112f9fa006917, []int{8}
}
func (m *DoubleHistogram) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_DoubleHistogram.Unmarshal(m, b)
}
func (m *DoubleHistogram) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_DoubleHistogram.Marshal(b, m, deterministic)
}
func (m *DoubleHistogram) XXX_Merge(src proto.Message) {
	xxx_messageInfo_DoubleHistogram.Merge(m, src)
}
func (m *DoubleHistogram) XXX_Size() int {
	return xxx_messageInfo_DoubleHistogram.Size(m)
}
func (m *DoubleHistogram) XXX_DiscardUnknown() {
	xxx_messageInfo_DoubleHistogram.DiscardUnknown(m)
}

var xxx_messageInfo_DoubleHistogram proto.InternalMessageInfo

func (m *DoubleHistogram) GetDataPoints() []*DoubleHistogramDataPoint {
	if m != nil {
		return m.DataPoints
	}
	return nil
}

func (m *DoubleHistogram) GetAggregationTemporality() AggregationTemporality {
	if m != nil {
		return m.AggregationTemporality
	}
	return AggregationTemporality_AGGREGATION_TEMPORALITY_UNSPECIFIED
}

// DoubleSummary metric data are used to convey quantile summaries,
// a Prometheus (see: https://prometheus.io/docs/concepts/metric_types/#summary)
// and OpenMetrics (see: https://github.com/OpenObservability/OpenMetrics/blob/4dbf6075567ab43296eed941037c12951faafb92/protos/prometheus.proto#L45)
// data type. These data points cannot always be merged in a meaningful way.
// While they can be useful in some applications, histogram data points are
// recommended for new applications.
type DoubleSummary struct {
	DataPoints           []*DoubleSummaryDataPoint `protobuf:"bytes,1,rep,name=data_points,json=dataPoints,proto3" json:"data_points,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                  `json:"-"`
	XXX_unrecognized     []byte                    `json:"-"`
	XXX_sizecache        int32                     `json:"-"`
}

func (m *DoubleSummary) Reset()         { *m = DoubleSummary{} }
func (m *DoubleSummary) String() string { return proto.CompactTextString(m) }
func (*DoubleSummary) ProtoMessage()    {}
func (*DoubleSummary) Descriptor() ([]byte, []int) {
	return fileDescriptor_3c3112f9fa006917, []int{9}
}
func (m *DoubleSummary) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_DoubleSummary.Unmarshal(m, b)
}
func (m *DoubleSummary) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_DoubleSummary.Marshal(b, m, deterministic)
}
func (m *DoubleSummary) XXX_Merge(src proto.Message) {
	xxx_messageInfo_DoubleSummary.Merge(m, src)
}
func (m *DoubleSummary) XXX_Size() int {
	return xxx_messageInfo_DoubleSummary.Size(m)
}
func (m *DoubleSummary) XXX_DiscardUnknown() {
	xxx_messageInfo_DoubleSummary.DiscardUnknown(m)
}

var xxx_messageInfo_DoubleSummary proto.InternalMessageInfo

func (m *DoubleSummary) GetDataPoints() []*DoubleSummaryDataPoint {
	if m != nil {
		return m.DataPoints
	}
	return nil
}

// IntDataPoint is a single data point in a timeseries that describes the
// time-varying values of a int64 metric.
type IntDataPoint struct {
	// The set of labels that uniquely identify this timeseries.
	Labels []*v11.StringKeyValue `protobuf:"bytes,1,rep,name=labels,proto3" json:"labels,omitempty"`
	// start_time_unix_nano is the last time when the aggregation value was reset
	// to "zero". For some metric types this is ignored, see data types for more
	// details.
	//
	// The aggregation value is over the time interval (start_time_unix_nano,
	// time_unix_nano].
	//
	// Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
	// 1970.
	//
	// Value of 0 indicates that the timestamp is unspecified. In that case the
	// timestamp may be decided by the backend.
	StartTimeUnixNano uint64 `protobuf:"fixed64,2,opt,name=start_time_unix_nano,json=startTimeUnixNano,proto3" json:"start_time_unix_nano,omitempty"`
	// time_unix_nano is the moment when this aggregation value was reported.
	//
	// Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
	// 1970.
	TimeUnixNano uint64 `protobuf:"fixed64,3,opt,name=time_unix_nano,json=timeUnixNano,proto3" json:"time_unix_nano,omitempty"`
	// value itself.
	Value int64 `protobuf:"fixed64,4,opt,name=value,proto3" json:"value,omitempty"`
	// (Optional) List of exemplars collected from
	// measurements that were used to form the data point
	Exemplars            []*IntExemplar `protobuf:"bytes,5,rep,name=exemplars,proto3" json:"exemplars,omitempty"`
	XXX_NoUnkeyedLiteral struct{}       `json:"-"`
	XXX_unrecognized     []byte         `json:"-"`
	XXX_sizecache        int32          `json:"-"`
}

func (m *IntDataPoint) Reset()         { *m = IntDataPoint{} }
func (m *IntDataPoint) String() string { return proto.CompactTextString(m) }
func (*IntDataPoint) ProtoMessage()    {}
func (*IntDataPoint) Descriptor() ([]byte, []int) {
	return fileDescriptor_3c3112f9fa006917, []int{10}
}
func (m *IntDataPoint) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_IntDataPoint.Unmarshal(m, b)
}
func (m *IntDataPoint) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_IntDataPoint.Marshal(b, m, deterministic)
}
func (m *IntDataPoint) XXX_Merge(src proto.Message) {
	xxx_messageInfo_IntDataPoint.Merge(m, src)
}
func (m *IntDataPoint) XXX_Size() int {
	return xxx_messageInfo_IntDataPoint.Size(m)
}
func (m *IntDataPoint) XXX_DiscardUnknown() {
	xxx_messageInfo_IntDataPoint.DiscardUnknown(m)
}

var xxx_messageInfo_IntDataPoint proto.InternalMessageInfo

func (m *IntDataPoint) GetLabels() []*v11.StringKeyValue {
	if m != nil {
		return m.Labels
	}
	return nil
}

func (m *IntDataPoint) GetStartTimeUnixNano() uint64 {
	if m != nil {
		return m.StartTimeUnixNano
	}
	return 0
}

func (m *IntDataPoint) GetTimeUnixNano() uint64 {
	if m != nil {
		return m.TimeUnixNano
	}
	return 0
}

func (m *IntDataPoint) GetValue() int64 {
	if m != nil {
		return m.Value
	}
	return 0
}

func (m *IntDataPoint) GetExemplars() []*IntExemplar {
	if m != nil {
		return m.Exemplars
	}
	return nil
}

// DoubleDataPoint is a single data point in a timeseries that describes the
// time-varying value of a double metric.
type DoubleDataPoint struct {
	// The set of labels that uniquely identify this timeseries.
	Labels []*v11.StringKeyValue `protobuf:"bytes,1,rep,name=labels,proto3" json:"labels,omitempty"`
	// start_time_unix_nano is the last time when the aggregation value was reset
	// to "zero". For some metric types this is ignored, see data types for more
	// details.
	//
	// The aggregation value is over the time interval (start_time_unix_nano,
	// time_unix_nano].
	//
	// Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
	// 1970.
	//
	// Value of 0 indicates that the timestamp is unspecified. In that case the
	// timestamp may be decided by the backend.
	StartTimeUnixNano uint64 `protobuf:"fixed64,2,opt,name=start_time_unix_nano,json=startTimeUnixNano,proto3" json:"start_time_unix_nano,omitempty"`
	// time_unix_nano is the moment when this aggregation value was reported.
	//
	// Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
	// 1970.
	TimeUnixNano uint64 `protobuf:"fixed64,3,opt,name=time_unix_nano,json=timeUnixNano,proto3" json:"time_unix_nano,omitempty"`
	// value itself.
	Value float64 `protobuf:"fixed64,4,opt,name=value,proto3" json:"value,omitempty"`
	// (Optional) List of exemplars collected from
	// measurements that were used to form the data point
	Exemplars            []*DoubleExemplar `protobuf:"bytes,5,rep,name=exemplars,proto3" json:"exemplars,omitempty"`
	XXX_NoUnkeyedLiteral struct{}          `json:"-"`
	XXX_unrecognized     []byte            `json:"-"`
	XXX_sizecache        int32             `json:"-"`
}

func (m *DoubleDataPoint) Reset()         { *m = DoubleDataPoint{} }
func (m *DoubleDataPoint) String() string { return proto.CompactTextString(m) }
func (*DoubleDataPoint) ProtoMessage()    {}
func (*DoubleDataPoint) Descriptor() ([]byte, []int) {
	return fileDescriptor_3c3112f9fa006917, []int{11}
}
func (m *DoubleDataPoint) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_DoubleDataPoint.Unmarshal(m, b)
}
func (m *DoubleDataPoint) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_DoubleDataPoint.Marshal(b, m, deterministic)
}
func (m *DoubleDataPoint) XXX_Merge(src proto.Message) {
	xxx_messageInfo_DoubleDataPoint.Merge(m, src)
}
func (m *DoubleDataPoint) XXX_Size() int {
	return xxx_messageInfo_DoubleDataPoint.Size(m)
}
func (m *DoubleDataPoint) XXX_DiscardUnknown() {
	xxx_messageInfo_DoubleDataPoint.DiscardUnknown(m)
}

var xxx_messageInfo_DoubleDataPoint proto.InternalMessageInfo

func (m *DoubleDataPoint) GetLabels() []*v11.StringKeyValue {
	if m != nil {
		return m.Labels
	}
	return nil
}

func (m *DoubleDataPoint) GetStartTimeUnixNano() uint64 {
	if m != nil {
		return m.StartTimeUnixNano
	}
	return 0
}

func (m *DoubleDataPoint) GetTimeUnixNano() uint64 {
	if m != nil {
		return m.TimeUnixNano
	}
	return 0
}

func (m *DoubleDataPoint) GetValue() float64 {
	if m != nil {
		return m.Value
	}
	return 0
}

func (m *DoubleDataPoint) GetExemplars() []*DoubleExemplar {
	if m != nil {
		return m.Exemplars
	}
	return nil
}

// IntHistogramDataPoint is a single data point in a timeseries that describes
// the time-varying values of a Histogram of int values. A Histogram contains
// summary statistics for a population of values, it may optionally contain
// the distribution of those values across a set of buckets.
type IntHistogramDataPoint struct {
	// The set of labels that uniquely identify this timeseries.
	Labels []*v11.StringKeyValue `protobuf:"bytes,1,rep,name=labels,proto3" json:"labels,omitempty"`
	// start_time_unix_nano is the last time when the aggregation value was reset
	// to "zero". For some metric types this is ignored, see data types for more
	// details.
	//
	// The aggregation value is over the time interval (start_time_unix_nano,
	// time_unix_nano].
	//
	// Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
	// 1970.
	//
	// Value of 0 indicates that the timestamp is unspecified. In that case the
	// timestamp may be decided by the backend.
	StartTimeUnixNano uint64 `protobuf:"fixed64,2,opt,name=start_time_unix_nano,json=startTimeUnixNano,proto3" json:"start_time_unix_nano,omitempty"`
	// time_unix_nano is the moment when this aggregation value was reported.
	//
	// Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
	// 1970.
	TimeUnixNano uint64 `protobuf:"fixed64,3,opt,name=time_unix_nano,json=timeUnixNano,proto3" json:"time_unix_nano,omitempty"`
	// count is the number of values in the population. Must be non-negative. This
	// value must be equal to the sum of the "count" fields in buckets if a
	// histogram is provided.
	Count uint64 `protobuf:"fixed64,4,opt,name=count,proto3" json:"count,omitempty"`
	// sum of the values in the population. If count is zero then this field
	// must be zero. This value must be equal to the sum of the "sum" fields in
	// buckets if a histogram is provided.
	Sum int64 `protobuf:"fixed64,5,opt,name=sum,proto3" json:"sum,omitempty"`
	// bucket_counts is an optional field contains the count values of histogram
	// for each bucket.
	//
	// The sum of the bucket_counts must equal the value in the count field.
	//
	// The number of elements in bucket_counts array must be by one greater than
	// the number of elements in explicit_bounds array.
	BucketCounts []uint64 `protobuf:"fixed64,6,rep,packed,name=bucket_counts,json=bucketCounts,proto3" json:"bucket_counts,omitempty"`
	// explicit_bounds specifies buckets with explicitly defined bounds for values.
	// The bucket boundaries are described by "bounds" field.
	//
	// This defines size(bounds) + 1 (= N) buckets. The boundaries for bucket
	// at index i are:
	//
	// (-infinity, bounds[i]) for i == 0
	// [bounds[i-1], bounds[i]) for 0 < i < N-1
	// [bounds[i], +infinity) for i == N-1
	// The values in bounds array must be strictly increasing.
	//
	// Note: only [a, b) intervals are currently supported for each bucket except the first one.
	// If we decide to also support (a, b] intervals we should add support for these by defining
	// a boolean value which decides what type of intervals to use.
	ExplicitBounds []float64 `protobuf:"fixed64,7,rep,packed,name=explicit_bounds,json=explicitBounds,proto3" json:"explicit_bounds,omitempty"`
	// (Optional) List of exemplars collected from
	// measurements that were used to form the data point
	Exemplars            []*IntExemplar `protobuf:"bytes,8,rep,name=exemplars,proto3" json:"exemplars,omitempty"`
	XXX_NoUnkeyedLiteral struct{}       `json:"-"`
	XXX_unrecognized     []byte         `json:"-"`
	XXX_sizecache        int32          `json:"-"`
}

func (m *IntHistogramDataPoint) Reset()         { *m = IntHistogramDataPoint{} }
func (m *IntHistogramDataPoint) String() string { return proto.CompactTextString(m) }
func (*IntHistogramDataPoint) ProtoMessage()    {}
func (*IntHistogramDataPoint) Descriptor() ([]byte, []int) {
	return fileDescriptor_3c3112f9fa006917, []int{12}
}
func (m *IntHistogramDataPoint) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_IntHistogramDataPoint.Unmarshal(m, b)
}
func (m *IntHistogramDataPoint) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_IntHistogramDataPoint.Marshal(b, m, deterministic)
}
func (m *IntHistogramDataPoint) XXX_Merge(src proto.Message) {
	xxx_messageInfo_IntHistogramDataPoint.Merge(m, src)
}
func (m *IntHistogramDataPoint) XXX_Size() int {
	return xxx_messageInfo_IntHistogramDataPoint.Size(m)
}
func (m *IntHistogramDataPoint) XXX_DiscardUnknown() {
	xxx_messageInfo_IntHistogramDataPoint.DiscardUnknown(m)
}

var xxx_messageInfo_IntHistogramDataPoint proto.InternalMessageInfo

func (m *IntHistogramDataPoint) GetLabels() []*v11.StringKeyValue {
	if m != nil {
		return m.Labels
	}
	return nil
}

func (m *IntHistogramDataPoint) GetStartTimeUnixNano() uint64 {
	if m != nil {
		return m.StartTimeUnixNano
	}
	return 0
}

func (m *IntHistogramDataPoint) GetTimeUnixNano() uint64 {
	if m != nil {
		return m.TimeUnixNano
	}
	return 0
}

func (m *IntHistogramDataPoint) GetCount() uint64 {
	if m != nil {
		return m.Count
	}
	return 0
}

func (m *IntHistogramDataPoint) GetSum() int64 {
	if m != nil {
		return m.Sum
	}
	return 0
}

func (m *IntHistogramDataPoint) GetBucketCounts() []uint64 {
	if m != nil {
		return m.BucketCounts
	}
	return nil
}

func (m *IntHistogramDataPoint) GetExplicitBounds() []float64 {
	if m != nil {
		return m.ExplicitBounds
	}
	return nil
}

func (m *IntHistogramDataPoint) GetExemplars() []*IntExemplar {
	if m != nil {
		return m.Exemplars
	}
	return nil
}

// HistogramDataPoint is a single data point in a timeseries that describes the
// time-varying values of a Histogram of double values. A Histogram contains
// summary statistics for a population of values, it may optionally contain the
// distribution of those values across a set of buckets.
type DoubleHistogramDataPoint struct {
	// The set of labels that uniquely identify this timeseries.
	Labels []*v11.StringKeyValue `protobuf:"bytes,1,rep,name=labels,proto3" json:"labels,omitempty"`
	// start_time_unix_nano is the last time when the aggregation value was reset
	// to "zero". For some metric types this is ignored, see data types for more
	// details.
	//
	// The aggregation value is over the time interval (start_time_unix_nano,
	// time_unix_nano].
	//
	// Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
	// 1970.
	//
	// Value of 0 indicates that the timestamp is unspecified. In that case the
	// timestamp may be decided by the backend.
	StartTimeUnixNano uint64 `protobuf:"fixed64,2,opt,name=start_time_unix_nano,json=startTimeUnixNano,proto3" json:"start_time_unix_nano,omitempty"`
	// time_unix_nano is the moment when this aggregation value was reported.
	//
	// Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
	// 1970.
	TimeUnixNano uint64 `protobuf:"fixed64,3,opt,name=time_unix_nano,json=timeUnixNano,proto3" json:"time_unix_nano,omitempty"`
	// count is the number of values in the population. Must be non-negative. This
	// value must be equal to the sum of the "count" fields in buckets if a
	// histogram is provided.
	Count uint64 `protobuf:"fixed64,4,opt,name=count,proto3" json:"count,omitempty"`
	// sum of the values in the population. If count is zero then this field
	// must be zero. This value must be equal to the sum of the "sum" fields in
	// buckets if a histogram is provided.
	Sum float64 `protobuf:"fixed64,5,opt,name=sum,proto3" json:"sum,omitempty"`
	// bucket_counts is an optional field contains the count values of histogram
	// for each bucket.
	//
	// The sum of the bucket_counts must equal the value in the count field.
	//
	// The number of elements in bucket_counts array must be by one greater than
	// the number of elements in explicit_bounds array.
	BucketCounts []uint64 `protobuf:"fixed64,6,rep,packed,name=bucket_counts,json=bucketCounts,proto3" json:"bucket_counts,omitempty"`
	// explicit_bounds specifies buckets with explicitly defined bounds for values.
	// The bucket boundaries are described by "bounds" field.
	//
	// This defines size(bounds) + 1 (= N) buckets. The boundaries for bucket
	// at index i are:
	//
	// (-infinity, bounds[i]) for i == 0
	// [bounds[i-1], bounds[i]) for 0 < i < N-1
	// [bounds[i], +infinity) for i == N-1
	// The values in bounds array must be strictly increasing.
	//
	// Note: only [a, b) intervals are currently supported for each bucket except the first one.
	// If we decide to also support (a, b] intervals we should add support for these by defining
	// a boolean value which decides what type of intervals to use.
	ExplicitBounds []float64 `protobuf:"fixed64,7,rep,packed,name=explicit_bounds,json=explicitBounds,proto3" json:"explicit_bounds,omitempty"`
	// (Optional) List of exemplars collected from
	// measurements that were used to form the data point
	Exemplars            []*DoubleExemplar `protobuf:"bytes,8,rep,name=exemplars,proto3" json:"exemplars,omitempty"`
	XXX_NoUnkeyedLiteral struct{}          `json:"-"`
	XXX_unrecognized     []byte            `json:"-"`
	XXX_sizecache        int32             `json:"-"`
}

func (m *DoubleHistogramDataPoint) Reset()         { *m = DoubleHistogramDataPoint{} }
func (m *DoubleHistogramDataPoint) String() string { return proto.CompactTextString(m) }
func (*DoubleHistogramDataPoint) ProtoMessage()    {}
func (*DoubleHistogramDataPoint) Descriptor() ([]byte, []int) {
	return fileDescriptor_3c3112f9fa006917, []int{13}
}
func (m *DoubleHistogramDataPoint) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_DoubleHistogramDataPoint.Unmarshal(m, b)
}
func (m *DoubleHistogramDataPoint) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_DoubleHistogramDataPoint.Marshal(b, m, deterministic)
}
func (m *DoubleHistogramDataPoint) XXX_Merge(src proto.Message) {
	xxx_messageInfo_DoubleHistogramDataPoint.Merge(m, src)
}
func (m *DoubleHistogramDataPoint) XXX_Size() int {
	return xxx_messageInfo_DoubleHistogramDataPoint.Size(m)
}
func (m *DoubleHistogramDataPoint) XXX_DiscardUnknown() {
	xxx_messageInfo_DoubleHistogramDataPoint.DiscardUnknown(m)
}

var xxx_messageInfo_DoubleHistogramDataPoint proto.InternalMessageInfo

func (m *DoubleHistogramDataPoint) GetLabels() []*v11.StringKeyValue {
	if m != nil {
		return m.Labels
	}
	return nil
}

func (m *DoubleHistogramDataPoint) GetStartTimeUnixNano() uint64 {
	if m != nil {
		return m.StartTimeUnixNano
	}
	return 0
}

func (m *DoubleHistogramDataPoint) GetTimeUnixNano() uint64 {
	if m != nil {
		return m.TimeUnixNano
	}
	return 0
}

func (m *DoubleHistogramDataPoint) GetCount() uint64 {
	if m != nil {
		return m.Count
	}
	return 0
}

func (m *DoubleHistogramDataPoint) GetSum() float64 {
	if m != nil {
		return m.Sum
	}
	return 0
}

func (m *DoubleHistogramDataPoint) GetBucketCounts() []uint64 {
	if m != nil {
		return m.BucketCounts
	}
	return nil
}

func (m *DoubleHistogramDataPoint) GetExplicitBounds() []float64 {
	if m != nil {
		return m.ExplicitBounds
	}
	return nil
}

func (m *DoubleHistogramDataPoint) GetExemplars() []*DoubleExemplar {
	if m != nil {
		return m.Exemplars
	}
	return nil
}

// DoubleSummaryDataPoint is a single data point in a timeseries that describes the
// time-varying values of a Summary metric.
type DoubleSummaryDataPoint struct {
	// The set of labels that uniquely identify this timeseries.
	Labels []*v11.StringKeyValue `protobuf:"bytes,1,rep,name=labels,proto3" json:"labels,omitempty"`
	// start_time_unix_nano is the last time when the aggregation value was reset
	// to "zero". For some metric types this is ignored, see data types for more
	// details.
	//
	// The aggregation value is over the time interval (start_time_unix_nano,
	// time_unix_nano].
	//
	// Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
	// 1970.
	//
	// Value of 0 indicates that the timestamp is unspecified. In that case the
	// timestamp may be decided by the backend.
	StartTimeUnixNano uint64 `protobuf:"fixed64,2,opt,name=start_time_unix_nano,json=startTimeUnixNano,proto3" json:"start_time_unix_nano,omitempty"`
	// time_unix_nano is the moment when this aggregation value was reported.
	//
	// Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
	// 1970.
	TimeUnixNano uint64 `protobuf:"fixed64,3,opt,name=time_unix_nano,json=timeUnixNano,proto3" json:"time_unix_nano,omitempty"`
	// count is the number of values in the population. Must be non-negative.
	Count uint64 `protobuf:"fixed64,4,opt,name=count,proto3" json:"count,omitempty"`
	// sum of the values in the population. If count is zero then this field
	// must be zero.
	Sum float64 `protobuf:"fixed64,5,opt,name=sum,proto3" json:"sum,omitempty"`
	// (Optional) list of values at different quantiles of the distribution calculated
	// from the current snapshot. The quantiles must be strictly increasing.
	QuantileValues       []*DoubleSummaryDataPoint_ValueAtQuantile `protobuf:"bytes,6,rep,name=quantile_values,json=quantileValues,proto3" json:"quantile_values,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                                  `json:"-"`
	XXX_unrecognized     []byte                                    `json:"-"`
	XXX_sizecache        int32                                     `json:"-"`
}

func (m *DoubleSummaryDataPoint) Reset()         { *m = DoubleSummaryDataPoint{} }
func (m *DoubleSummaryDataPoint) String() string { return proto.CompactTextString(m) }
func (*DoubleSummaryDataPoint) ProtoMessage()    {}
func (*DoubleSummaryDataPoint) Descriptor() ([]byte, []int) {
	return fileDescriptor_3c3112f9fa006917, []int{14}
}
func (m *DoubleSummaryDataPoint) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_DoubleSummaryDataPoint.Unmarshal(m, b)
}
func (m *DoubleSummaryDataPoint) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_DoubleSummaryDataPoint.Marshal(b, m, deterministic)
}
func (m *DoubleSummaryDataPoint) XXX_Merge(src proto.Message) {
	xxx_messageInfo_DoubleSummaryDataPoint.Merge(m, src)
}
func (m *DoubleSummaryDataPoint) XXX_Size() int {
	return xxx_messageInfo_DoubleSummaryDataPoint.Size(m)
}
func (m *DoubleSummaryDataPoint) XXX_DiscardUnknown() {
	xxx_messageInfo_DoubleSummaryDataPoint.DiscardUnknown(m)
}

var xxx_messageInfo_DoubleSummaryDataPoint proto.InternalMessageInfo

func (m *DoubleSummaryDataPoint) GetLabels() []*v11.StringKeyValue {
	if m != nil {
		return m.Labels
	}
	return nil
}

func (m *DoubleSummaryDataPoint) GetStartTimeUnixNano() uint64 {
	if m != nil {
		return m.StartTimeUnixNano
	}
	return 0
}

func (m *DoubleSummaryDataPoint) GetTimeUnixNano() uint64 {
	if m != nil {
		return m.TimeUnixNano
	}
	return 0
}

func (m *DoubleSummaryDataPoint) GetCount() uint64 {
	if m != nil {
		return m.Count
	}
	return 0
}

func (m *DoubleSummaryDataPoint) GetSum() float64 {
	if m != nil {
		return m.Sum
	}
	return 0
}

func (m *DoubleSummaryDataPoint) GetQuantileValues() []*DoubleSummaryDataPoint_ValueAtQuantile {
	if m != nil {
		return m.QuantileValues
	}
	return nil
}

// Represents the value at a given quantile of a distribution.
//
// To record Min and Max values following conventions are used:
// - The 1.0 quantile is equivalent to the maximum value observed.
// - The 0.0 quantile is equivalent to the minimum value observed.
//
// See the following issue for more context:
// https://github.com/open-telemetry/opentelemetry-proto/issues/125
type DoubleSummaryDataPoint_ValueAtQuantile struct {
	// The quantile of a distribution. Must be in the interval
	// [0.0, 1.0].
	Quantile float64 `protobuf:"fixed64,1,opt,name=quantile,proto3" json:"quantile,omitempty"`
	// The value at the given quantile of a distribution.
	Value                float64  `protobuf:"fixed64,2,opt,name=value,proto3" json:"value,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *DoubleSummaryDataPoint_ValueAtQuantile) Reset() {
	*m = DoubleSummaryDataPoint_ValueAtQuantile{}
}
func (m *DoubleSummaryDataPoint_ValueAtQuantile) String() string { return proto.CompactTextString(m) }
func (*DoubleSummaryDataPoint_ValueAtQuantile) ProtoMessage()    {}
func (*DoubleSummaryDataPoint_ValueAtQuantile) Descriptor() ([]byte, []int) {
	return fileDescriptor_3c3112f9fa006917, []int{14, 0}
}
func (m *DoubleSummaryDataPoint_ValueAtQuantile) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_DoubleSummaryDataPoint_ValueAtQuantile.Unmarshal(m, b)
}
func (m *DoubleSummaryDataPoint_ValueAtQuantile) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_DoubleSummaryDataPoint_ValueAtQuantile.Marshal(b, m, deterministic)
}
func (m *DoubleSummaryDataPoint_ValueAtQuantile) XXX_Merge(src proto.Message) {
	xxx_messageInfo_DoubleSummaryDataPoint_ValueAtQuantile.Merge(m, src)
}
func (m *DoubleSummaryDataPoint_ValueAtQuantile) XXX_Size() int {
	return xxx_messageInfo_DoubleSummaryDataPoint_ValueAtQuantile.Size(m)
}
func (m *DoubleSummaryDataPoint_ValueAtQuantile) XXX_DiscardUnknown() {
	xxx_messageInfo_DoubleSummaryDataPoint_ValueAtQuantile.DiscardUnknown(m)
}

var xxx_messageInfo_DoubleSummaryDataPoint_ValueAtQuantile proto.InternalMessageInfo

func (m *DoubleSummaryDataPoint_ValueAtQuantile) GetQuantile() float64 {
	if m != nil {
		return m.Quantile
	}
	return 0
}

func (m *DoubleSummaryDataPoint_ValueAtQuantile) GetValue() float64 {
	if m != nil {
		return m.Value
	}
	return 0
}

// A representation of an exemplar, which is a sample input int measurement.
// Exemplars also hold information about the environment when the measurement
// was recorded, for example the span and trace ID of the active span when the
// exemplar was recorded.
type IntExemplar struct {
	// The set of labels that were filtered out by the aggregator, but recorded
	// alongside the original measurement. Only labels that were filtered out
	// by the aggregator should be included
	FilteredLabels []*v11.StringKeyValue `protobuf:"bytes,1,rep,name=filtered_labels,json=filteredLabels,proto3" json:"filtered_labels,omitempty"`
	// time_unix_nano is the exact time when this exemplar was recorded
	//
	// Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
	// 1970.
	TimeUnixNano uint64 `protobuf:"fixed64,2,opt,name=time_unix_nano,json=timeUnixNano,proto3" json:"time_unix_nano,omitempty"`
	// Numerical int value of the measurement that was recorded.
	Value int64 `protobuf:"fixed64,3,opt,name=value,proto3" json:"value,omitempty"`
	// (Optional) Span ID of the exemplar trace.
	// span_id may be missing if the measurement is not recorded inside a trace
	// or if the trace is not sampled.
	SpanId []byte `protobuf:"bytes,4,opt,name=span_id,json=spanId,proto3" json:"span_id,omitempty"`
	// (Optional) Trace ID of the exemplar trace.
	// trace_id may be missing if the measurement is not recorded inside a trace
	// or if the trace is not sampled.
	TraceId              []byte   `protobuf:"bytes,5,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *IntExemplar) Reset()         { *m = IntExemplar{} }
func (m *IntExemplar) String() string { return proto.CompactTextString(m) }
func (*IntExemplar) ProtoMessage()    {}
func (*IntExemplar) Descriptor() ([]byte, []int) {
	return fileDescriptor_3c3112f9fa006917, []int{15}
}
func (m *IntExemplar) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_IntExemplar.Unmarshal(m, b)
}
func (m *IntExemplar) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_IntExemplar.Marshal(b, m, deterministic)
}
func (m *IntExemplar) XXX_Merge(src proto.Message) {
	xxx_messageInfo_IntExemplar.Merge(m, src)
}
func (m *IntExemplar) XXX_Size() int {
	return xxx_messageInfo_IntExemplar.Size(m)
}
func (m *IntExemplar) XXX_DiscardUnknown() {
	xxx_messageInfo_IntExemplar.DiscardUnknown(m)
}

var xxx_messageInfo_IntExemplar proto.InternalMessageInfo

func (m *IntExemplar) GetFilteredLabels() []*v11.StringKeyValue {
	if m != nil {
		return m.FilteredLabels
	}
	return nil
}

func (m *IntExemplar) GetTimeUnixNano() uint64 {
	if m != nil {
		return m.TimeUnixNano
	}
	return 0
}

func (m *IntExemplar) GetValue() int64 {
	if m != nil {
		return m.Value
	}
	return 0
}

func (m *IntExemplar) GetSpanId() []byte {
	if m != nil {
		return m.SpanId
	}
	return nil
}

func (m *IntExemplar) GetTraceId() []byte {
	if m != nil {
		return m.TraceId
	}
	return nil
}

// A representation of an exemplar, which is a sample input double measurement.
// Exemplars also hold information about the environment when the measurement
// was recorded, for example the span and trace ID of the active span when the
// exemplar was recorded.
type DoubleExemplar struct {
	// The set of labels that were filtered out by the aggregator, but recorded
	// alongside the original measurement. Only labels that were filtered out
	// by the aggregator should be included
	FilteredLabels []*v11.StringKeyValue `protobuf:"bytes,1,rep,name=filtered_labels,json=filteredLabels,proto3" json:"filtered_labels,omitempty"`
	// time_unix_nano is the exact time when this exemplar was recorded
	//
	// Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
	// 1970.
	TimeUnixNano uint64 `protobuf:"fixed64,2,opt,name=time_unix_nano,json=timeUnixNano,proto3" json:"time_unix_nano,omitempty"`
	// Numerical double value of the measurement that was recorded.
	Value float64 `protobuf:"fixed64,3,opt,name=value,proto3" json:"value,omitempty"`
	// (Optional) Span ID of the exemplar trace.
	// span_id may be missing if the measurement is not recorded inside a trace
	// or if the trace is not sampled.
	SpanId []byte `protobuf:"bytes,4,opt,name=span_id,json=spanId,proto3" json:"span_id,omitempty"`
	// (Optional) Trace ID of the exemplar trace.
	// trace_id may be missing if the measurement is not recorded inside a trace
	// or if the trace is not sampled.
	TraceId              []byte   `protobuf:"bytes,5,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *DoubleExemplar) Reset()         { *m = DoubleExemplar{} }
func (m *DoubleExemplar) String() string { return proto.CompactTextString(m) }
func (*DoubleExemplar) ProtoMessage()    {}
func (*DoubleExemplar) Descriptor() ([]byte, []int) {
	return fileDescriptor_3c3112f9fa006917, []int{16}
}
func (m *DoubleExemplar) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_DoubleExemplar.Unmarshal(m, b)
}
func (m *DoubleExemplar) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_DoubleExemplar.Marshal(b, m, deterministic)
}
func (m *DoubleExemplar) XXX_Merge(src proto.Message) {
	xxx_messageInfo_DoubleExemplar.Merge(m, src)
}
func (m *DoubleExemplar) XXX_Size() int {
	return xxx_messageInfo_DoubleExemplar.Size(m)
}
func (m *DoubleExemplar) XXX_DiscardUnknown() {
	xxx_messageInfo_DoubleExemplar.DiscardUnknown(m)
}

var xxx_messageInfo_DoubleExemplar proto.InternalMessageInfo

func (m *DoubleExemplar) GetFilteredLabels() []*v11.StringKeyValue {
	if m != nil {
		return m.FilteredLabels
	}
	return nil
}

func (m *DoubleExemplar) GetTimeUnixNano() uint64 {
	if m != nil {
		return m.TimeUnixNano
	}
	return 0
}

func (m *DoubleExemplar) GetValue() float64 {
	if m != nil {
		return m.Value
	}
	return 0
}

func (m *DoubleExemplar) GetSpanId() []byte {
	if m != nil {
		return m.SpanId
	}
	return nil
}

func (m *DoubleExemplar) GetTraceId() []byte {
	if m != nil {
		return m.TraceId
	}
	return nil
}

func init() {
	proto.RegisterEnum("opentelemetry.proto.metrics.v1.AggregationTemporality", AggregationTemporality_name, AggregationTemporality_value)
	proto.RegisterType((*ResourceMetrics)(nil), "opentelemetry.proto.metrics.v1.ResourceMetrics")
	proto.RegisterType((*InstrumentationLibraryMetrics)(nil), "opentelemetry.proto.metrics.v1.InstrumentationLibraryMetrics")
	proto.RegisterType((*Metric)(nil), "opentelemetry.proto.metrics.v1.Metric")
	proto.RegisterType((*IntGauge)(nil), "opentelemetry.proto.metrics.v1.IntGauge")
	proto.RegisterType((*DoubleGauge)(nil), "opentelemetry.proto.metrics.v1.DoubleGauge")
	proto.RegisterType((*IntSum)(nil), "opentelemetry.proto.metrics.v1.IntSum")
	proto.RegisterType((*DoubleSum)(nil), "opentelemetry.proto.metrics.v1.DoubleSum")
	proto.RegisterType((*IntHistogram)(nil), "opentelemetry.proto.metrics.v1.IntHistogram")
	proto.RegisterType((*DoubleHistogram)(nil), "opentelemetry.proto.metrics.v1.DoubleHistogram")
	proto.RegisterType((*DoubleSummary)(nil), "opentelemetry.proto.metrics.v1.DoubleSummary")
	proto.RegisterType((*IntDataPoint)(nil), "opentelemetry.proto.metrics.v1.IntDataPoint")
	proto.RegisterType((*DoubleDataPoint)(nil), "opentelemetry.proto.metrics.v1.DoubleDataPoint")
	proto.RegisterType((*IntHistogramDataPoint)(nil), "opentelemetry.proto.metrics.v1.IntHistogramDataPoint")
	proto.RegisterType((*DoubleHistogramDataPoint)(nil), "opentelemetry.proto.metrics.v1.DoubleHistogramDataPoint")
	proto.RegisterType((*DoubleSummaryDataPoint)(nil), "opentelemetry.proto.metrics.v1.DoubleSummaryDataPoint")
	proto.RegisterType((*DoubleSummaryDataPoint_ValueAtQuantile)(nil), "opentelemetry.proto.metrics.v1.DoubleSummaryDataPoint.ValueAtQuantile")
	proto.RegisterType((*IntExemplar)(nil), "opentelemetry.proto.metrics.v1.IntExemplar")
	proto.RegisterType((*DoubleExemplar)(nil), "opentelemetry.proto.metrics.v1.DoubleExemplar")
}

func init() {
	proto.RegisterFile("opentelemetry/proto/metrics/v1/metrics.proto", fileDescriptor_3c3112f9fa006917)
}

var fileDescriptor_3c3112f9fa006917 = []byte{
	// 1165 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xdc, 0x58, 0xcf, 0x6f, 0xe3, 0xc4,
	0x17, 0xaf, 0x93, 0xcd, 0xaf, 0x97, 0x34, 0xc9, 0x77, 0xb4, 0xdf, 0xae, 0xa9, 0x54, 0x68, 0xbd,
	0xa8, 0x5b, 0x76, 0xb7, 0x89, 0x5a, 0xb4, 0x2b, 0x2e, 0x08, 0xd2, 0x36, 0xdb, 0x06, 0xd2, 0x6e,
	0x98, 0xa6, 0x45, 0x45, 0x48, 0x96, 0x13, 0x0f, 0xe9, 0x08, 0x7b, 0x1c, 0xec, 0x71, 0xd5, 0xfe,
	0x01, 0xdc, 0x40, 0x1c, 0xe0, 0x1f, 0xe3, 0x80, 0xe0, 0x82, 0xc4, 0x9d, 0x13, 0x17, 0x4e, 0x1c,
	0xd0, 0x8c, 0xed, 0xc6, 0x69, 0xdd, 0x26, 0xa5, 0x8b, 0xd4, 0xe5, 0xf6, 0xe6, 0xfd, 0xf8, 0xcc,
	0x7b, 0x9f, 0x79, 0xf3, 0xe2, 0x0c, 0x3c, 0x75, 0x86, 0x84, 0x71, 0x62, 0x11, 0x9b, 0x70, 0xf7,
	0xac, 0x3e, 0x74, 0x1d, 0xee, 0xd4, 0x85, 0x4c, 0xfb, 0x5e, 0xfd, 0x64, 0x2d, 0x12, 0x6b, 0xd2,
	0x80, 0xde, 0x1c, 0xf3, 0x0e, 0x94, 0xb5, 0xc8, 0xe5, 0x64, 0x6d, 0xfe, 0x71, 0x12, 0x5a, 0xdf,
	0xb1, 0x6d, 0x87, 0x09, 0xb0, 0x40, 0x0a, 0xc2, 0xe6, 0x6b, 0x49, 0xbe, 0x2e, 0xf1, 0x1c, 0xdf,
	0xed, 0x13, 0xe1, 0x1d, 0xc9, 0x81, 0xbf, 0xf6, 0x9b, 0x02, 0x15, 0x1c, 0xaa, 0x76, 0x83, 0x2d,
	0x51, 0x13, 0xf2, 0x91, 0x97, 0xaa, 0x2c, 0x2a, 0x2b, 0xc5, 0xf5, 0x77, 0x6a, 0x49, 0x29, 0x9e,
	0x43, 0x9d, 0xac, 0xd5, 0x22, 0x0c, 0x7c, 0x1e, 0x8a, 0xbe, 0x56, 0xe0, 0x2d, 0xca, 0x3c, 0xee,
	0xfa, 0x36, 0x61, 0xdc, 0xe0, 0xd4, 0x61, 0xba, 0x45, 0x7b, 0xae, 0xe1, 0x9e, 0xe9, 0x61, 0x75,
	0x6a, 0x6a, 0x31, 0xbd, 0x52, 0x5c, 0x7f, 0xbf, 0x76, 0x3d, 0x03, 0xb5, 0xd6, 0x38, 0x4c, 0x3b,
	0x40, 0x09, 0xf3, 0xc5, 0x0b, 0xf4, 0x3a, 0xb3, 0xf6, 0xa3, 0x02, 0x0b, 0xd7, 0x02, 0x20, 0x06,
	0x0f, 0xae, 0x48, 0x34, 0xac, 0xff, 0x59, 0x62, 0x82, 0x21, 0xf1, 0x57, 0xe6, 0x87, 0xe7, 0x92,
	0x13, 0x43, 0x1f, 0x42, 0x6e, 0x9c, 0x80, 0xe5, 0x49, 0x04, 0x04, 0x99, 0xe2, 0x28, 0x4c, 0xfb,
	0x2e, 0x03, 0xd9, 0x40, 0x87, 0x10, 0xdc, 0x63, 0x86, 0x1d, 0x9c, 0x54, 0x01, 0x4b, 0x19, 0x2d,
	0x42, 0xd1, 0x24, 0x5e, 0xdf, 0xa5, 0x43, 0xb1, 0xad, 0x9a, 0x92, 0xa6, 0xb8, 0x4a, 0x44, 0xf9,
	0x8c, 0x72, 0x35, 0x1d, 0x44, 0x09, 0x19, 0x6d, 0x43, 0x81, 0x32, 0xae, 0x0f, 0x0c, 0x7f, 0x40,
	0xd4, 0x7b, 0xb2, 0xf0, 0x95, 0xc9, 0x27, 0xc3, 0xb7, 0x85, 0xff, 0xce, 0x0c, 0xce, 0xd3, 0x50,
	0x46, 0x1d, 0x28, 0x99, 0x8e, 0xdf, 0xb3, 0x48, 0x88, 0x95, 0x91, 0x58, 0x4f, 0x26, 0x61, 0x6d,
	0xc9, 0x98, 0x08, 0xae, 0x68, 0x8e, 0x96, 0xa8, 0x01, 0x39, 0x91, 0x9a, 0xe7, 0xdb, 0x6a, 0x56,
	0x82, 0x2d, 0x4f, 0x91, 0xd8, 0xbe, 0x6f, 0xef, 0xcc, 0xe0, 0x2c, 0x95, 0x12, 0xfa, 0x08, 0x20,
	0x4c, 0x4a, 0xa0, 0xe4, 0xae, 0xe9, 0xeb, 0x4b, 0x29, 0x05, 0x40, 0x05, 0x33, 0x5a, 0xa0, 0x7d,
	0x98, 0x15, 0xe9, 0x1c, 0x53, 0x8f, 0x3b, 0x03, 0xd7, 0xb0, 0xd5, 0xbc, 0x84, 0x7b, 0x3a, 0x45,
	0x52, 0x3b, 0x51, 0xcc, 0xce, 0x0c, 0x2e, 0xd1, 0xd8, 0x1a, 0x7d, 0x0e, 0xd5, 0x30, 0xc1, 0x11,
	0x6e, 0x41, 0xe2, 0xd6, 0xa7, 0x4b, 0x33, 0x0e, 0x5d, 0x31, 0xc7, 0x55, 0xe8, 0x10, 0xca, 0xa3,
	0xf2, 0x6d, 0xd1, 0xda, 0x45, 0x89, 0xbd, 0x3a, 0x35, 0x05, 0x22, 0x68, 0x67, 0x06, 0xcf, 0x9a,
	0x71, 0xc5, 0x46, 0x16, 0xee, 0x99, 0x06, 0x37, 0xb4, 0x23, 0xc8, 0x47, 0xbd, 0x80, 0x76, 0xa1,
	0x28, 0x74, 0xfa, 0xd0, 0xa1, 0x8c, 0x7b, 0xaa, 0x22, 0x7b, 0x7c, 0x1a, 0x72, 0xb6, 0x0c, 0x6e,
	0x74, 0x44, 0x10, 0x06, 0x33, 0x12, 0x3d, 0x4d, 0x87, 0x62, 0xac, 0x35, 0x50, 0x27, 0x09, 0x7d,
	0x4a, 0x8a, 0x92, 0x37, 0xf8, 0x5d, 0x81, 0x6c, 0xd0, 0x2f, 0xaf, 0x38, 0x75, 0xe4, 0xc0, 0x03,
	0x63, 0x30, 0x70, 0xc9, 0x20, 0x98, 0x2a, 0x9c, 0xd8, 0x43, 0xc7, 0x35, 0x2c, 0xca, 0xcf, 0xe4,
	0xa5, 0x2c, 0xaf, 0x3f, 0x9f, 0x04, 0xdd, 0x18, 0x85, 0x77, 0x47, 0xd1, 0x78, 0xce, 0x48, 0xd4,
	0xa3, 0x25, 0x28, 0x51, 0x4f, 0xb7, 0x1d, 0xe6, 0x70, 0x87, 0xd1, 0xbe, 0xbc, 0xdf, 0x79, 0x5c,
	0xa4, 0xde, 0x6e, 0xa4, 0xd2, 0xfe, 0x50, 0xa0, 0x70, 0x7e, 0xa8, 0xaf, 0x9e, 0xcd, 0x3b, 0x59,
	0xf3, 0xcf, 0x0a, 0x94, 0xe2, 0x97, 0x0f, 0x1d, 0x26, 0x95, 0xfd, 0xec, 0x26, 0xf7, 0xf7, 0x6e,
	0x14, 0xaf, 0xfd, 0xaa, 0x40, 0xe5, 0xc2, 0xf5, 0x47, 0x47, 0x49, 0xc5, 0xbd, 0x77, 0xc3, 0x21,
	0x72, 0x47, 0xea, 0x3b, 0x86, 0xd9, 0xb1, 0x09, 0x84, 0x3e, 0x4d, 0x2a, 0xee, 0xf9, 0x8d, 0xa6,
	0x58, 0xf2, 0x14, 0xf8, 0x36, 0x25, 0x7b, 0xe4, 0xdc, 0x88, 0x9a, 0x90, 0xb5, 0x8c, 0x1e, 0xb1,
	0xa2, 0x4d, 0x56, 0x27, 0x7c, 0x05, 0xec, 0x73, 0x97, 0xb2, 0xc1, 0xc7, 0xe4, 0xec, 0xd0, 0xb0,
	0x7c, 0x82, 0xc3, 0x60, 0x54, 0x87, 0xfb, 0x1e, 0x37, 0x5c, 0xae, 0x73, 0x6a, 0x13, 0xdd, 0x67,
	0xf4, 0x54, 0x67, 0x06, 0x73, 0x24, 0x5f, 0x59, 0xfc, 0x3f, 0x69, 0xeb, 0x52, 0x9b, 0x1c, 0x30,
	0x7a, 0xba, 0x67, 0x30, 0x07, 0xbd, 0x0d, 0xe5, 0x0b, 0xae, 0x69, 0xe9, 0x5a, 0xe2, 0x71, 0xaf,
	0xfb, 0x90, 0x39, 0x11, 0xfb, 0xc8, 0x5f, 0xea, 0x2a, 0x0e, 0x16, 0xa8, 0x05, 0x05, 0x72, 0x4a,
	0xec, 0xa1, 0x65, 0xb8, 0x9e, 0x9a, 0x91, 0x69, 0x3f, 0x99, 0xa2, 0xab, 0x9b, 0x61, 0x0c, 0x1e,
	0x45, 0x6b, 0xdf, 0xa7, 0xa2, 0xce, 0x7a, 0x2d, 0x29, 0x51, 0x22, 0x4a, 0xda, 0x97, 0x29, 0xa9,
	0x4d, 0xd7, 0x2e, 0x49, 0xac, 0xfc, 0x99, 0x82, 0xff, 0x27, 0x8e, 0x81, 0xbb, 0xcf, 0x4d, 0xdf,
	0xf1, 0x19, 0x97, 0xdc, 0x64, 0x71, 0xb0, 0x40, 0x55, 0x48, 0x8b, 0xaf, 0xa1, 0x8c, 0x6c, 0x21,
	0x21, 0xa2, 0x87, 0x30, 0xdb, 0xf3, 0xfb, 0x5f, 0x12, 0xae, 0x4b, 0x0f, 0x4f, 0xcd, 0x2e, 0xa6,
	0x05, 0x58, 0xa0, 0xdc, 0x94, 0x3a, 0xf4, 0x08, 0x2a, 0xe4, 0x74, 0x68, 0xd1, 0x3e, 0xe5, 0x7a,
	0xcf, 0xf1, 0x99, 0xe9, 0xa9, 0xb9, 0xc5, 0xf4, 0x8a, 0x82, 0xcb, 0x91, 0x7a, 0x43, 0x6a, 0xc7,
	0xdb, 0x31, 0x7f, 0xab, 0x76, 0xfc, 0x2b, 0x05, 0xea, 0x55, 0x23, 0xea, 0x75, 0xe7, 0x5e, 0xf9,
	0x37, 0xb8, 0x6f, 0x5f, 0xe6, 0xfe, 0x16, 0x7d, 0xff, 0x43, 0x1a, 0xe6, 0x92, 0x87, 0xe8, 0x7f,
	0x84, 0x7c, 0x07, 0x2a, 0x5f, 0xf9, 0x06, 0xe3, 0xd4, 0x22, 0xba, 0x1c, 0x1c, 0x01, 0xfd, 0xc5,
	0xf5, 0x17, 0xff, 0xec, 0xb7, 0xa5, 0x26, 0xab, 0x6b, 0xf0, 0x4f, 0x42, 0x50, 0x5c, 0x8e, 0xe0,
	0xa5, 0xc1, 0x9b, 0xdf, 0x84, 0xca, 0x05, 0x17, 0x34, 0x0f, 0xf9, 0xc8, 0x49, 0xfe, 0x9f, 0x53,
	0xf0, 0xf9, 0x7a, 0x34, 0xdc, 0x52, 0xb1, 0xe1, 0xa6, 0xfd, 0xa4, 0x40, 0x31, 0x76, 0x61, 0xd0,
	0x21, 0x54, 0xbe, 0xa0, 0x16, 0x27, 0x2e, 0x31, 0xf5, 0xdb, 0x1c, 0x4a, 0x39, 0x42, 0x69, 0x07,
	0x87, 0x73, 0x99, 0xeb, 0xd4, 0x75, 0x03, 0x38, 0x1d, 0xff, 0x4d, 0x7a, 0x00, 0x39, 0x6f, 0x68,
	0x30, 0x9d, 0x9a, 0xf2, 0x0c, 0x4a, 0x38, 0x2b, 0x96, 0x2d, 0x13, 0xbd, 0x01, 0x79, 0xee, 0x1a,
	0x7d, 0x22, 0x2c, 0x19, 0x69, 0xc9, 0xc9, 0x75, 0xcb, 0xd4, 0x7e, 0x51, 0xa0, 0x3c, 0xde, 0x8c,
	0x77, 0xa9, 0x34, 0xe5, 0x16, 0xa5, 0x3d, 0xfe, 0x46, 0x81, 0xb9, 0xe4, 0x8f, 0x20, 0xf4, 0x08,
	0x1e, 0x36, 0xb6, 0xb7, 0x71, 0x73, 0xbb, 0xd1, 0x6d, 0xbd, 0xdc, 0xd3, 0xbb, 0xcd, 0xdd, 0xce,
	0x4b, 0xdc, 0x68, 0xb7, 0xba, 0x47, 0xfa, 0xc1, 0xde, 0x7e, 0xa7, 0xb9, 0xd9, 0x7a, 0xd1, 0x6a,
	0x6e, 0x55, 0x67, 0xd0, 0x12, 0x2c, 0x5c, 0xe5, 0xb8, 0xd5, 0x6c, 0x77, 0x1b, 0x55, 0x05, 0x2d,
	0x83, 0x76, 0x95, 0xcb, 0xe6, 0xc1, 0xee, 0x41, 0xbb, 0xd1, 0x6d, 0x1d, 0x36, 0xab, 0xa9, 0x0d,
	0x0e, 0x4b, 0xd4, 0x99, 0xd0, 0xe2, 0x1b, 0xa5, 0xf0, 0xa9, 0xa4, 0x23, 0x0c, 0x1d, 0xe5, 0xb3,
	0x0f, 0x06, 0x94, 0x1f, 0xfb, 0x3d, 0x41, 0x72, 0x5d, 0x84, 0xae, 0x8e, 0x9e, 0x9c, 0xc6, 0x90,
	0x56, 0x83, 0x07, 0xa8, 0x01, 0x61, 0xf5, 0x41, 0xfc, 0x05, 0xac, 0x97, 0x95, 0x86, 0x77, 0xff,
	0x0e, 0x00, 0x00, 0xff, 0xff, 0xa1, 0xd3, 0x84, 0x30, 0x2a, 0x13, 0x00, 0x00,
}
